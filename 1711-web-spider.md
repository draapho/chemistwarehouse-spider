---
title: 使用网络爬虫抓取商品价格并分析
date: 2017-04-10
categories: python
tags: [embedded, linux, jz2440]
---


# 需求分析

基于 [Chemist Warehouse](http://www.chemistwarehouse.com.au/) 的商品, 抓取其每天的价格变化. 并根据历史信息, 判断其价格变化规律, 以便在打折时购买.

因此, 用户需求有如下几点:
- 抓取网站价格, 需要知道其商品全名, 原价, 打折价, 打折日期, 持续时间
- 存储这些数据, 供日后分析使用
- 数据挖掘和分析, 已直观的方式多维度显示出来(譬如单品的打折规律, 打折力度, 打折持续时间. 全年的打折规律)

进一步, 技术分析如下:
- 全程使用python即可满足全部需求.
- 网络爬虫难度不高, 仅需针对特定商品, 每天抓一次, 无需多线程/进程, 无需登录, 无验证码, 无需考虑反爬虫, 无需额外加载JS程序.
- 数据存储, 使用MySQL, 数据需要去重, 仅记录关键信息. 以便减少数据存储量, 简化数据挖掘和分析的工作
- 数据图表显示, 使用 matplotlib 即可.

成果, 


# 网络爬虫

花了二天时间, 简单过了一遍网络爬虫的关键技术. 参考资料如下:
- [Python爬虫学习系列教程-静觅](http://cuiqingcai.com/1052.html)
- [Python入门网络爬虫之精华版](https://github.com/lining0806/PythonSpiderNotes)


本着项目导向, 做出结果为先的思路, 没有一步步的实验. 上来先看了几个爬虫框架.
- `pyspider` 基于web UI, 感觉很直观, 适合于随便玩玩. 个人不喜欢, 二次开发不方便.
- python 下另外一个很有名的框架就是 `scrapy`, 可惜我连配置安装都没有成功的做完. 适合二次开发.
- 使用 `requests` `urllib` `lxml` 库. 简单项目直接用这个就够了.
- 最终抓数据我只用了 `lxml` 一个库就完成了数据抓取, 去重的工作.




----------

***原创于 [DRA&PHO](https://draapho.github.io/)***
